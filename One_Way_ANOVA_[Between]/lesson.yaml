- Class: meta
  Course: Psychological Statistics You Can Handle
  Lesson: One-Way ANOVA [Between]
  Author: Kevin R. Carriere & Jason Kilgore
  Type: Standard
  Organization: Washington & Jefferson College
  Version: 3.0.0

- Class: script
  Output: Here are some notes for this module. When you've saved the notes, type submit().
  AnswerTests: script_results_identical('saved')
  Hint: Make sure the last line in your script says saved <- "Y".
  Script: Notes.R

- Class: text
  Output: While t-tests can test the difference between Group 1 and Group 2, they cannot test the difference between Group 1, 2, and 3. To do that, we would need to run three different t-tests (1-2; 2-3; 1-3).

- Class: text
  Output: This risks inflating our Type I error rate and finding significant differences when the truth is that they are not different. An ANOVA is an omnibus test - it asks, "Is there differences between these groups?" without stating where those differences lie. 

- Class: text
  Output: "We are going to analyze data published on Psychological Science. This study aimed to determine how much Soloman's paradox holds true: do we reason more about other individuals' problems than our own?"
  
- Class: text
  Output: "The citation is Grossmann, I., & Kross, E. (2014). Exploring Solomon’s Paradox- Self-Distancing Eliminates the Self-Other Asymmetry in Wise Reasoning About Close Relationships in Younger and Older Adults. Psychological Science, 25(8), 1571–1580. doi.org/10.1177/0956797614535400"

- Class: cmd_question
  Output: We've loaded the data into your environment called Solomon. Let's look at it by piping Solomon into head().
  CorrectAnswer: Solomon |> head()
  AnswerTests: omnitest(correctExpr='Solomon |> head()')
  Hint: Try Solomon |> head(). 

- Class: text
  Output: Notice there are two columns - one that lumps all conditions together (Condition) and one that represents the response variable, how much wisdom is attributed. 

- Class: cmd_question
  Output: How many levels are in this condition? Let's check by taking our data, Solomon, and then (|>) select()ing the column Condition, and then (|>) using the function table(). 
  CorrectAnswer:  Solomon |> select(Condition) |> table()
  AnswerTests: any_of_exprs('Solomon |> select(Condition) |> table()', 'Solomon |> dplyr::select(Condition) |> table()', 'table(Solomon$Condition)')
  Hint: Try Solomon |> select(Condition) |> table(). 

- Class: text
  Output: Great. We have four levels of a single variable. 

- Class: text
  Output: Participants were randomly assigned to one of 4 conditions to imagine a scenario in which their partner had cheated on either them or their friend's partner had cheated on them and asked to write a response on how to handle the situation.

- Class: text
  Output: These responses were rated on how wise the participant's response was. Let us do an ANOVA to test whether or not there was a difference in condition.
  
- Class: cmd_question
  Output: There are many ways we can approach this question, and the notes go through many ways as well. We will take our data, Solomon, for this module and pipe it through the lm() function. In the lm() function, include two arguments - Wisdom ~ Condition (signifying we want to predict Wisdom based on our condition), and data=_, which means that the data is whatever is on the left side of the pipe. Be sure to save what you've done as wis_model. 
  CorrectAnswer:  wis_model <- Solomon |> lm(Wisdom ~ Condition, data=_)
  AnswerTests: omnitest(correctExpr='wis_model <- Solomon |> lm(Wisdom ~ Condition, data=_)')
  Hint: Try wis_model <- Solomon |> lm(Wisdom ~ Condition, data=_)  

- Class: cmd_question
  Output: Now that you've created and saved a linear model (that's what lm stands for), we can look at it in a few different ways. Let's look at it in the way we might be taught - as an ANOVA. take wis_model and pipe it into anova().
  CorrectAnswer:  wis_model |> anova()
  AnswerTests: omnitest(correctExpr='wis_model |> anova()')
  Hint: Try wis_model |> anova()

- Class: cmd_question
  Output: Great! Now that you've taken a linear model (lm()) and piped it into an anova(), you should notice this is the classic ANOVA table you may have been taught. Indeed, all ANOVAs are simply linear models, just with (what we think is) less meaningful information provided to the reader. To see the linear regression output, pipe wis_model into summary().
  CorrectAnswer:  wis_model |> summary()
  AnswerTests: omnitest(correctExpr='wis_model |> summary()')
  Hint: Try wis_model |> summary()

- Class: text
  Output: Great job. We recommend you look at the regression module to understand what is going on here completely. Briefly, we see all four levels of our Condition - (Other-Distanced is represented by (Intercept)). Moreover, the Estimates are the other three levels and their difference in score compared to the base category of Other-Distanced. That means that Other_Distanced has an average of .3345, while Other-Immersed is .1396 less than Other-Distanced. We also can tell that this comparison is not significantly different (p=.575).

- Class: cmd_question
  Output: Don't believe us? Let's prove it. Take your data, Solomon, and pipe it into group_by(), where we will give it a single argument Condition, and then pipe that into summarise(), where we will pass it one argument, WisMean = mean(Wisdom, na.rm=TRUE)
  CorrectAnswer:  Solomon |> group_by(Condition) |> summarise(WisMean = mean(Wisdom, na.rm=TRUE))
  AnswerTests: omnitest(correctExpr='Solomon |> group_by(Condition) |> summarise(WisMean = mean(Wisdom, na.rm=TRUE))')
  Hint: Try Solomon |> group_by(Condition) |> summarise(WisMean = mean(Wisdom, na.rm=TRUE)).

- Class: text
  Output: And now we can see how the (Intercept) represents the WisMean for Other-Distanced. How neat! 

- Class: cmd_question
  Output: We can do post-hoc tests in a variety of ways. We outline a few others in the notes, but let's proceed with the workhorse method of post-hoc tests. We'll pipe our model, wis_model, into the emmeans() function from the emmeans() library. In that function, we'll give it a single argument, ~Condition (telling it to make estimated marginal means by Condition).
  CorrectAnswer:  wis_model |> emmeans(~Condition)
  AnswerTests: omnitest(correctExpr='wis_model |> emmeans(~Condition)')
  Hint: Try wis_model |> emmeans(~Condition)

- Class: cmd_question
  Output: That was great, but it didn't tell us anything about the significance. Hit the up arrow key to go back to that code. From there, pipe all of that into the function pairs(). Try that now. 
  CorrectAnswer:  wis_model |> emmeans(~Condition) |> pairs()
  AnswerTests: omnitest(correctExpr='wis_model |> emmeans(~Condition) |> pairs()')
  Hint: Try wis_model |> emmeans(~Condition) |> pairs()
  
- Class: text
  Output: Now, this is very different from planned contrasts. A post-hoc is generally done when you haven't made any a priori assumptions about where you think significance will lie. Because of this, we correct the alpha value needed to reach statistical significance. But, if you knew what you wanted to test ahead of time, you could use planned contrasts instead. 
  
- Class: text
  Output: That's exactly what the authors of this paper did. They write - We performed planned contrasts- Participants in the other-immersed and other-distanced conditions showed higher levels of wisdom than participants in the self-immersed condition, t(113) = 3.93, p < .001, ηp2 = .12.

- Class: text
  Output: A good sign of planned contrasts is that they compare multiple groups at once - did you catch how they combined the OTHER conditions against the singular self-immersed condition? That's not possible using Tukey or any post-hoc test.
  
- Class: text
  Output: There are some critical notes about performing planned contrasts.

- Class: text
  Output: "1. The sum of the coefficients for a particular contrast must equal zero. \n\n 2. Groups of means to be averaged together are assigned the same coefficient. \n\n 3. Means not included in the comparison of a particular contrast are assigned a coefficient of 0.  \n\n 4. If there are A treatment groups, at most, there can be (A-1) orthogonal contrasts (although there are many possible sets of orthogonal contrasts) \n\n 5. All pair-wise cross products (of the coefficients) must sum to zero across all contrasts."
  
- Class: text
  Output: "Above, when we did model |> emmeans() without pairs, you might have noticed that the factors are listed in a specific order -  O-D, O-I, S-D, S-I."
  
- Class: text
  Output: "This represents a list of numbers. The quote above had them wanting to compare Other-Distance AND Other-Immersed against Self-Immersed. We can represent this through numbers. Consider that O-D is the first in the list, O-I is the second, S-D is the third, and S-I is the 4th in the list."

- Class: cmd_question
  Output:  Let's create a new object called Comparisons, and we'll assign it to the function list(). This function will get a single argument, OthervSI = c(-1, -1, 0, 2). Notice four numbers - for the four conditions! Since S-D is not in the comparison, we zero out the third in the list, and since O-D and O-I are going to be combined, we keep them in the same negative direction and have them be sure that if we add up the comparison list, it would equal zero. Try that now. 
  CorrectAnswer:  Comparisons <- list(OthervSI = c(-1,-1,0, 2))
  AnswerTests: omnitest(correctExpr='Comparisons <- list(OthervSI = c(-1,-1,0, 2))')
  Hint: Try Comparisons <- list(OthervSI = c(-1,-1,0, 2))

- Class: cmd_question
  Output: Great. Now, let's combine what we've done. Hit up until you get to that emmeans(~Condition) piece (without pairs()). Now pipe and add the contrast() function with the single argument, Comparisons.
  CorrectAnswer: wis_model |> emmeans(~Condition) |> contrast(Comparisons)
  AnswerTests: omnitest(correctExpr='wis_model |> emmeans(~Condition) |> contrast(Comparisons)')
  Hint: Try wis_model |> emmeans(~Condition) |> contrast(Comparisons).

- Class: cmd_question
  Output: Very good. Our df is two less - we're not sure why. Regardless, hit up until you get back to the Comparisons = list(). After your first one, add a comma after 2). Then, the next comparison they want is SD (the 3rd level) compared against SI (the 4th level). Write that contrast just like the first one, and call it SDvSI. 
  CorrectAnswer: Comparisons = list(OthervSI = c(-1,-1,0, 2), SDvSI = c(0,0,-1,1))
  AnswerTests: any_of_exprs('Comparisons = list(OthervSI = c(-1,-1,0, 2), SDvSI = c(0,0,-1,1))', 'Comparisons = list(OthervSI = c(-1,-1,0, 2), SDvSI = c(0,0,1,-1))')
  Hint: Try Comparisons = list(OthervSI = c(-1,-1,0, 2), SDvSI = c(0,0,-1,1))

- Class: cmd_question
  Output: Great. Now hit up and re-run that contrast(Comparisons) code line - now that we've re-saved the Comparisons object, it'll look a bit different. 
  CorrectAnswer: wis_model |> emmeans(~Condition) |> contrast(Comparisons)
  AnswerTests: omnitest(correctExpr='wis_model |> emmeans(~Condition) |> contrast(Comparisons)')
  Hint: Try wis_model |> emmeans(~Condition) |> contrast(Comparisons).

- Class: cmd_question
  Output: Great job. The last thing we'll do - we go into it in more depth in the notes - is show how we can use this output to create significantly different letter combinations. Go back to where we had emmeans(~Condition) and pipe a new function, cld(), from the multcomp package. We'll pass it a single argument, Letters = letters. 
  CorrectAnswer: wis_model |> emmeans(~Condition) |> cld(Letters = letters) 
  AnswerTests: omnitest(correctExpr='wis_model |> emmeans(~Condition) |> cld(Letters = letters)')
  Hint: wis_model |> emmeans(~Condition) |> cld(Letters = letters) 

- Class: text
  Output: Now you have a dataset of means (emmean), standard errors (SE), confidence intervals (lower.CL and upper.CL) and labels for your graph (.group). In the notes, we take this and plot it using ggplot2. 


- Class: text
  Output: And that's a one way ANOVA! As a review, to run an ANOVA, you create a linear model and then use the anova() wrapper on it. To test for post-hocs, use emmeans([variable]) |> pairs(). 

- Class: mult_question
  Output: Would you like to submit the log of this lesson to Google Forms so that your instructor may evaluate your progress?
  AnswerChoices: Yes;No
  CorrectAnswer: NULL
  AnswerTests: submit_log()
  Hint: hint
